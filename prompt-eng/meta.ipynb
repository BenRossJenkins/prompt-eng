{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Prompting\n",
    "\n",
    "Meta prompting is an advanced technique in prompt engineering that emphasizes the structural and syntactical organization of tasks and problems rather than focusing on their specific content. The objective is to create a more abstract, form-driven way of engaging with large language models (LLMs), highlighting patterns and structure over traditional content-focused methods.\n",
    "\n",
    "As outlined by [Zhang et al. (2024)](https://arxiv.org/abs/2311.11482), the defining features of meta prompting include:\n",
    "\n",
    "* Structure-Oriented: Prioritizes the organization and pattern of problems and solutions instead of specific content.\n",
    "* Syntax-Guided: Leverages syntax as a template to shape the expected responses or solutions.\n",
    "* Abstract Frameworks: Uses abstract examples as blueprints, demonstrating the structure of tasks without relying on concrete details.\n",
    "* Domain Versatility: Can be applied across multiple fields, offering structured solutions to diverse problem types.\n",
    "* Categorical Approach: Draws on type theory to organize and categorize components logically, enhancing prompt coherence and precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'mistral', 'prompt': '\\nYou are an AI hiring assistant trained in resume screening. Before answering, first generate the **best possible prompt** to analyze a job description and a candidate\\'s resume.\\n\\n---\\n\\n### **Example Prompt Generation**:\\n**Generated Prompt:**  \\n\"Analyze the following job description and resume. Extract key job requirements, candidate qualifications, compare them, and provide a structured match score along with hiring recommendations.\"\\n\\n---\\n\\nNow, generate a similar prompt for the following job description and resume:\\n\\n**Job Description:**  \\n\\nWe are hiring a Data Scientist with expertise in Python, Machine Learning, and SQL.\\nThe candidate must have at least 3 years of experience and a background in statistical modeling.\\nExperience with cloud platforms (AWS, GCP) is a plus.\\n  \\n\\n**Candidate Resume:**  \\n\\nJohn Doe is a Data Scientist with 4 years of experience. Skilled in Python, Machine Learning,\\nand SQL. He has worked on predictive modeling projects and statistical analysis.\\nFamiliar with AWS but lacks GCP experience.\\n  \\n\\nAfter generating the prompt, **use it to analyze the resume and return a structured evaluation. Keep it concise**.\\n', 'stream': False, 'options': {'temperature': 0.7, 'num_ctx': 1026, 'num_predict': 450, 'stream': True}}\n",
      " \"Evaluate the following job description and candidate's resume. Identify key job requirements and candidate qualifications, compare them, and provide a structured match score along with hiring recommendations.\n",
      "\n",
      "Job Description: Data Scientist with 3+ years of experience, expertise in Python, Machine Learning, SQL, background in statistical modeling, and preferably experience with cloud platforms (AWS, GCP).\n",
      "\n",
      "Candidate Resume: John Doe is a Data Scientist with 4 years of experience, skilled in Python, Machine Learning, and SQL. He has worked on predictive modeling projects and statistical analysis but lacks GCP experience.\n",
      "\n",
      "Match Score (Out of 5): 4\n",
      "\n",
      "Hiring Recommendation: The candidate's qualifications align well with the job requirements except for the GCP experience. Given his strong background in Python, Machine Learning, SQL, and predictive modeling, he could be a good fit if provided with an opportunity to learn GCP during the tenure. It is recommended to schedule an interview to assess his problem-solving skills and cultural fit.\"\n",
      "Time taken: 37.995s\n"
     ]
    }
   ],
   "source": [
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Adjust the inbounding Prompt, simulating inbounding requests from users or other systems\n",
    "JOB_DESCRIPTION = \"\"\"\n",
    "We are hiring a Data Scientist with expertise in Python, Machine Learning, and SQL.\n",
    "The candidate must have at least 3 years of experience and a background in statistical modeling.\n",
    "Experience with cloud platforms (AWS, GCP) is a plus.\n",
    "\"\"\"\n",
    "\n",
    "RESUME = \"\"\"\n",
    "John Doe is a Data Scientist with 4 years of experience. Skilled in Python, Machine Learning,\n",
    "and SQL. He has worked on predictive modeling projects and statistical analysis.\n",
    "Familiar with AWS but lacks GCP experience.\n",
    "\"\"\"\n",
    "\n",
    "#### (2) Adjust the Meta-Prompting Technique\n",
    "META_PROMPT = f\"\"\"\n",
    "You are an AI hiring assistant trained in resume screening. Before answering, first generate the **best possible prompt** to analyze a job description and a candidate's resume.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example Prompt Generation**:\n",
    "**Generated Prompt:**  \n",
    "\"Analyze the following job description and resume. Extract key job requirements, candidate qualifications, compare them, and provide a structured match score along with hiring recommendations.\"\n",
    "\n",
    "---\n",
    "\n",
    "Now, generate a similar prompt for the following job description and resume:\n",
    "\n",
    "**Job Description:**  \n",
    "{JOB_DESCRIPTION}  \n",
    "\n",
    "**Candidate Resume:**  \n",
    "{RESUME}  \n",
    "\n",
    "After generating the prompt, **use it to analyze the resume and return a structured evaluation. Keep it concise**.\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = META_PROMPT\n",
    "\n",
    "#### (3) Configure the Model Request\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"mistral\",  \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=0.7,  \n",
    "                         num_ctx=1026,\n",
    "                         num_predict=450,  # Ensures concise responses\n",
    "                         stream=True)  # Enable streaming for better performance\n",
    "\n",
    "### YOU DON'T NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad9dbb30419f39d3b950511a054b90c1a8968e921652cfa6c101cb7f52ff5baa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
