{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template Prompting\n",
    "\n",
    "Prompt Template Prompting refers to a technique where predefined templates are used to construct effective prompts that guide large language models (LLMs) to generate responses tailored to specific use cases. The templates typically contain static text combined with dynamic input variables, allowing for consistent, reusable, and customizable prompts.\n",
    "\n",
    "Prompt templates are widely used across various domains, such as:\n",
    "* **Question Generation**: Templates can generate quiz questions by filling in variables related to topics.\n",
    "* **Text Summarization**: Static instructions combined with variable documents or inputs allow flexible summarization.\n",
    "* **Coding Assistance**: Dynamic prompts help LLMs generate code snippets for different programming tasks.\n",
    "\n",
    "## References:\n",
    "\n",
    "* (OpenAI Documentation for Prompt Engineering)[https://platform.openai.com/docs/guides/prompt-engineering]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fprompt_template.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1848.47\n",
      "Time taken: 3.297s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## PROMPT TEMPLATE PROMPTING\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Adjust the inbounding  Prompt, simulating inbounding requests from users or other systems\n",
    "MESSAGE = \"984 * log(2)\"\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "TEMPLATE_BEFORE=\"Act like you are a math teacher. Answer to this question from an student:\"\n",
    "TEMPLATE_AFTER=\"Provide the answer only. No explanations!\"\n",
    "PROMPT = TEMPLATE_BEFORE + '\\n' + MESSAGE + '\\n' + TEMPLATE_AFTER\n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=1.0, \n",
    "                         num_ctx=100, \n",
    "                         num_predict=100)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'mistral', 'prompt': \"\\nYou are an AI hiring assistant. Your task is to analyze job descriptions and resumes to determine a candidate's fit for a role.\\nFollow the structured format below to ensure clarity.\\n\\n\\n**Job Description:**\\n\\nWe are hiring a Data Scientist with expertise in Python, Machine Learning, and SQL.\\nThe candidate must have at least 3 years of experience and a background in statistical modeling.\\nExperience with cloud platforms (AWS, GCP) is a plus.\\n\\n\\n**Candidate Resume:**\\n\\nJohn Doe is a Data Scientist with 4 years of experience. Skilled in Python, Machine Learning,\\nand SQL. He has worked on predictive modeling projects and statistical analysis.\\nFamiliar with AWS but lacks GCP experience.\\n\\n\\n\\nProvide only the structured evaluation, match score, and hiring recommendation. No explanations beyond the requested sections.\\n\", 'stream': False, 'options': {'temperature': 0.7, 'num_ctx': 768, 'num_predict': 300, 'stream': True}}\n",
      " **Evaluation:**\n",
      "      - Python: Match\n",
      "      - Machine Learning: Match\n",
      "      - SQL: Match\n",
      "      - Statistical Modeling: Match\n",
      "      - Cloud Platforms (AWS): Strong Match\n",
      "      - Cloud Platforms (GCP): No Match\n",
      "      - Years of Experience: Slight Overqualification (4 years vs 3 years required)\n",
      "\n",
      "   **Match Score:** 0.85\n",
      "\n",
      "   **Hiring Recommendation:** The candidate, John Doe, is a strong match for the Data Scientist role with his skills in Python, Machine Learning, and SQL. However, he lacks experience with Google Cloud Platform (GCP). It is recommended to consider this as a learning opportunity or provide additional training for GCP if necessary.\n",
      "Time taken: 41.795s\n"
     ]
    }
   ],
   "source": [
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Adjust the inbounding Prompt, simulating inbounding requests from users or other systems\n",
    "JOB_DESCRIPTION = \"\"\"\n",
    "We are hiring a Data Scientist with expertise in Python, Machine Learning, and SQL.\n",
    "The candidate must have at least 3 years of experience and a background in statistical modeling.\n",
    "Experience with cloud platforms (AWS, GCP) is a plus.\n",
    "\"\"\"\n",
    "\n",
    "RESUME = \"\"\"\n",
    "John Doe is a Data Scientist with 4 years of experience. Skilled in Python, Machine Learning,\n",
    "and SQL. He has worked on predictive modeling projects and statistical analysis.\n",
    "Familiar with AWS but lacks GCP experience.\n",
    "\"\"\"\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "TEMPLATE_BEFORE = \"\"\"\n",
    "You are an AI hiring assistant. Your task is to analyze job descriptions and resumes to determine a candidate's fit for a role.\n",
    "Follow the structured format below to ensure clarity.\n",
    "\"\"\"\n",
    "\n",
    "TEMPLATE_AFTER = \"\"\"\n",
    "Provide only the structured evaluation, match score, and hiring recommendation. No explanations beyond the requested sections.\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = TEMPLATE_BEFORE + \"\\n\\n**Job Description:**\\n\" + JOB_DESCRIPTION + \"\\n\\n**Candidate Resume:**\\n\" + RESUME + \"\\n\\n\" + TEMPLATE_AFTER\n",
    "\n",
    "#### (3) Configure the Model Request\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"mistral\",  \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=0.7,  \n",
    "                         num_ctx=768,  # Optimized for speed\n",
    "                         num_predict=300,  # Ensures full response generation\n",
    "                         stream=True)  # Enable streaming for better performance\n",
    "\n",
    "### YOU DON'T NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad9dbb30419f39d3b950511a054b90c1a8968e921652cfa6c101cb7f52ff5baa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
