{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain-of-Thought Prompting\n",
    "\n",
    "Chain-of-Thought (CoT) prompting enhances complex reasoning by encouraging the model to break down problems into intermediate reasoning steps. When combined with few-shot prompting, it can significantly improve performance on tasks that require multi-step reasoning before arriving at a response.\n",
    "\n",
    "## Automatic Chain-of-Thought (Auto-CoT)\n",
    "\n",
    "Traditionally, using CoT prompting with demonstrations involves manually crafting diverse and effective examples. This manual effort is time-consuming and can lead to less-than-optimal results. To address this, Zhang et al. (2022) introduced Auto-CoT, an automated approach that minimizes manual involvement. Their method uses the prompt “Let’s think step by step” to generate reasoning chains automatically for demonstrations. However, this automatic process is not immune to errors. To reduce the impact of such mistakes, the approach emphasizes the importance of diverse demonstrations.\n",
    "\n",
    "Auto-CoT operates in two main stages:\n",
    "\n",
    "1. **Question Clustering:** Questions from the dataset are grouped into clusters based on similarity or relevance.\n",
    "2. **Demonstration Sampling:** A representative question from each cluster is selected, and its reasoning chain is generated using Zero-Shot-CoT guided by simple heuristics.\n",
    "\n",
    "\n",
    "## References:\n",
    "\n",
    "* (Wei et al. (2022),)[https://arxiv.org/abs/2201.11903]\n",
    "* (OpenAI Documentation for Prompt Engineering)[https://platform.openai.com/docs/guides/prompt-engineering]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fchain_of_thought.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': '\\nThe odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\\nA: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False.\\nThe odd numbers in this group add up to an even number: 17,  10, 19, 4, 8, 12, 24.\\nA: Adding all the odd numbers (17, 19) gives 36. The answer is True.\\nThe odd numbers in this group add up to an even number: 16,  11, 14, 4, 8, 13, 24.\\nA: Adding all the odd numbers (11, 13) gives 24. The answer is True.\\nThe odd numbers in this group add up to an even number: 17,  9, 10, 12, 13, 4, 2.\\nA: Adding all the odd numbers (17, 9, 13) gives 39. The answer is False.\\nNow Add all odd numbers until 200 and let me know. \\nProvide only the answer, no explanation!\\n', 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 100, 'num_predict': 100}}\n",
      "False\n",
      "Time taken: 6.317s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## CHAIN-OF-THOUGHT  PROMPTING\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "\n",
    "#### (1) Adjust the inbounding  Prompt, simulating inbounding requests from users or other systems\n",
    "MESSAGE = \"200\"\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "CHAIN_OF_THOUGHT = \\\n",
    "f\"\"\"\n",
    "The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
    "A: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False.\n",
    "The odd numbers in this group add up to an even number: 17,  10, 19, 4, 8, 12, 24.\n",
    "A: Adding all the odd numbers (17, 19) gives 36. The answer is True.\n",
    "The odd numbers in this group add up to an even number: 16,  11, 14, 4, 8, 13, 24.\n",
    "A: Adding all the odd numbers (11, 13) gives 24. The answer is True.\n",
    "The odd numbers in this group add up to an even number: 17,  9, 10, 12, 13, 4, 2.\n",
    "A: Adding all the odd numbers (17, 9, 13) gives 39. The answer is False.\n",
    "Now Add all odd numbers until {MESSAGE} and let me know. \n",
    "Provide only the answer, no explanation!\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = CHAIN_OF_THOUGHT \n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=1.0, \n",
    "                         num_ctx=100, \n",
    "                         num_predict=100)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'mistral', 'prompt': \"\\nYou are an AI-powered hiring assistant. Your task is to analyze a job description \\nand compare it with a candidate's resume using a structured reasoning process.\\n\\n**Step 1: Extract Key Job Requirements**  \\nIdentify the hard skills, soft skills, required experience, and certifications from the job description.\\n\\n**Step 2: Extract Candidate Qualifications**  \\nIdentify the skills, experience, and certifications from the resume.\\n\\n**Step 3: Compare Requirements vs. Candidate Skills**  \\nMatch each job requirement with the candidate’s qualifications. Identify gaps.\\n\\n**Step 4: Assign a Match Score**  \\nBased on the overlap, provide a match percentage (0-100%). Justify the score.\\n\\n---  \\n**Job Description:**  \\n\\nWe are hiring a Data Scientist with expertise in Python, Machine Learning, and SQL.\\nThe candidate must have at least 3 years of experience and a background in statistical modeling.\\nExperience with cloud platforms (AWS, GCP) is a plus.\\n  \\n\\n---  \\n**Candidate Resume:**  \\n\\nJohn Doe is a Data Scientist with 4 years of experience. Skilled in Python, Machine Learning,\\nand SQL. He has worked on predictive modeling projects and statistical analysis.\\nFamiliar with AWS but lacks GCP experience.\\n  \\n\\n**Now analyze the job description and resume step by step, and provide a match score. Keep the response concise. Use bullet points for clarity.**\\n**Provide recommendations for the candidate to improve their match score. Keep it concise.**\\n\", 'stream': False, 'options': {'temperature': 0.7, 'num_ctx': 1026, 'num_predict': 350, 'stream': True}}\n",
      "1. **Job Requirements:**\n",
      "   - Skills: Python, Machine Learning, SQL\n",
      "   - Experience: Minimum 3 years\n",
      "   - Background: Statistical modeling\n",
      "   - Plus: Experience with cloud platforms (AWS, GCP)\n",
      "\n",
      "2. **Candidate Qualifications:**\n",
      "   - Skills: Python, Machine Learning, SQL\n",
      "   - Experience: 4 years\n",
      "   - Background: Predictive modeling projects and statistical analysis\n",
      "   - Cloud Platforms: AWS (familiar)\n",
      "\n",
      "3. **Comparison:**\n",
      "   - Skills: Match\n",
      "   - Experience: Close match (4 years vs. 3 years minimum)\n",
      "   - Background: Match\n",
      "   - Plus: Partial match (AWS experience but lacks GCP)\n",
      "\n",
      "4. **Match Score:**\n",
      "   80% (John Doe has most of the required skills and experience, but lacks GCP experience.)\n",
      "\n",
      "**Recommendations for Candidate:**\n",
      "- Acquire hands-on experience with Google Cloud Platform (GCP) to meet the \"plus\" requirement.\n",
      "- Highlight specific statistical modeling projects in resume or cover letter to emphasize background match.\n",
      "Time taken: 41.434s\n"
     ]
    }
   ],
   "source": [
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Adjust the inbounding  Prompt, simulating inbounding requests from users or other systems\n",
    "JOB_DESCRIPTION = \"\"\"\n",
    "We are hiring a Data Scientist with expertise in Python, Machine Learning, and SQL.\n",
    "The candidate must have at least 3 years of experience and a background in statistical modeling.\n",
    "Experience with cloud platforms (AWS, GCP) is a plus.\n",
    "\"\"\"\n",
    "\n",
    "RESUME = \"\"\"\n",
    "John Doe is a Data Scientist with 4 years of experience. Skilled in Python, Machine Learning,\n",
    "and SQL. He has worked on predictive modeling projects and statistical analysis.\n",
    "Familiar with AWS but lacks GCP experience.\n",
    "\"\"\"\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "CHAIN_OF_THOUGHT = f\"\"\"\n",
    "You are an AI-powered hiring assistant. Your task is to analyze a job description \n",
    "and compare it with a candidate's resume using a structured reasoning process.\n",
    "\n",
    "**Step 1: Extract Key Job Requirements**  \n",
    "Identify the hard skills, soft skills, required experience, and certifications from the job description.\n",
    "\n",
    "**Step 2: Extract Candidate Qualifications**  \n",
    "Identify the skills, experience, and certifications from the resume.\n",
    "\n",
    "**Step 3: Compare Requirements vs. Candidate Skills**  \n",
    "Match each job requirement with the candidate’s qualifications. Identify gaps.\n",
    "\n",
    "**Step 4: Assign a Match Score**  \n",
    "Based on the overlap, provide a match percentage (0-100%). Justify the score.\n",
    "\n",
    "---  \n",
    "**Job Description:**  \n",
    "{JOB_DESCRIPTION}  \n",
    "\n",
    "---  \n",
    "**Candidate Resume:**  \n",
    "{RESUME}  \n",
    "\n",
    "**Now analyze the job description and resume step by step, and provide a match score. Keep the response concise. Use bullet points for clarity.**\n",
    "**Provide recommendations for the candidate to improve their match score. Keep it concise.**\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = CHAIN_OF_THOUGHT\n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"mistral\",  # Use a valid installed model\n",
    "                         prompt=PROMPT, \n",
    "                         temperature=0.7,  \n",
    "                         num_ctx=1026,  \n",
    "                         num_predict=350,\n",
    "                         stream=True)  # Enable streaming for better performance\n",
    "\n",
    "### YOU DON'T NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad9dbb30419f39d3b950511a054b90c1a8968e921652cfa6c101cb7f52ff5baa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
